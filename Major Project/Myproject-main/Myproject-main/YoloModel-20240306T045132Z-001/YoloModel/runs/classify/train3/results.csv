                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                0.72653,                0.92381,                      1,                0.68499,             0.00023589,             0.00023589,             0.00023589
                      2,                  0.223,                0.90476,                      1,                0.64809,             0.00045044,             0.00045044,             0.00045044
                      3,                0.17591,                 0.9619,                      1,                0.60317,             0.00064142,             0.00064142,             0.00064142
                      4,                0.11009,                0.97619,                      1,                0.58259,             0.00060797,             0.00060797,             0.00060797
                      5,                0.09846,                0.94762,                      1,                0.60707,             0.00060797,             0.00060797,             0.00060797
                      6,                0.06712,                0.97619,                      1,                0.57666,             0.00057263,             0.00057263,             0.00057263
                      7,                0.07738,                0.99048,                      1,                0.56822,             0.00053728,             0.00053728,             0.00053728
                      8,                0.06018,                0.97143,                      1,                0.58371,             0.00050194,             0.00050194,             0.00050194
                      9,                0.06061,                0.98571,                      1,                0.57331,              0.0004666,              0.0004666,              0.0004666
                     10,                0.08604,                0.99048,                      1,                0.56787,             0.00043126,             0.00043126,             0.00043126
                     11,                0.06112,                0.98571,                      1,                0.56738,             0.00039591,             0.00039591,             0.00039591
                     12,                0.04919,                0.99048,                      1,                0.56613,             0.00036057,             0.00036057,             0.00036057
                     13,                0.04623,                      1,                      1,                0.55671,             0.00032523,             0.00032523,             0.00032523
                     14,                0.04504,                0.99524,                      1,                0.55797,             0.00028988,             0.00028988,             0.00028988
                     15,                0.03876,                0.99048,                      1,                0.56069,             0.00025454,             0.00025454,             0.00025454
                     16,                0.03265,                0.99524,                      1,                0.55811,              0.0002192,              0.0002192,              0.0002192
                     17,                0.02596,                      1,                      1,                0.55629,             0.00018385,             0.00018385,             0.00018385
                     18,                  0.025,                0.99048,                      1,                0.56292,             0.00014851,             0.00014851,             0.00014851
                     19,                0.02398,                0.99524,                      1,                 0.5588,             0.00011317,             0.00011317,             0.00011317
                     20,                0.03602,                0.99524,                      1,                0.55936,             7.7826e-05,             7.7826e-05,             7.7826e-05
